{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Archive my tweets\n",
    "\n",
    "- badges: true\n",
    "- categories: [code, twitter]\n",
    "- hide: false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I want to extract all the tweets I've ever written and convert them to small markdown files so they show up as \"posts\" on this website.\n",
    "\n",
    "Posts are organized by date, in the traditional blogging format. But so are tweets, kind of? They're listed chronologically anyway. Maybe I could make one post for each day, and then have all the tweets listed on that page. Each one could have its tweet ID as a header, thus having an internal link. Tweets can link to the tweets that precede them, and maybe even backlink to tweets that follow.\n",
    "\n",
    "It's not quite block references, but as a way of keeping my second brain under my ownership it should work. And this way if anyone wants to cancel me they'll have a convenient search box and permalinks for it. Even if my account gets deleted, my bad takes can stay up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:49:53.508536Z",
     "iopub.status.busy": "2021-11-24T16:49:53.507974Z",
     "iopub.status.idle": "2021-11-24T16:49:53.529914Z",
     "shell.execute_reply": "2021-11-24T16:49:53.529358Z",
     "shell.execute_reply.started": "2021-11-24T16:49:53.508373Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-11-23'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the last date i ran this\n",
    "from pathlib import Path\n",
    "out_dir = Path('../_posts/tweets/')\n",
    "posts = [o.name for o in out_dir.iterdir()]\n",
    "\n",
    "last_date = sorted(posts)[-2][:10]\n",
    "\n",
    "last_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This :point_up: is a workaround. Sometime after I started archiving my tweets, Twitter changed the API for search. This means that unofficial scrapers like `twint`stopped being able to see tweets from more than a few months ago. Even the in-app search was broken for a while.\n",
    "\n",
    "Fortunately I had already scraped and archived my old tweets, so now I just check to see when the last time I ran this script was and find tweets since that date. This also helps protect me from getting rate-limited by Twitter (they tend to do that if you download 30,000 tweets a few times in a row lol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:49:53.531272Z",
     "iopub.status.busy": "2021-11-24T16:49:53.531038Z",
     "iopub.status.idle": "2021-11-24T16:50:17.560879Z",
     "shell.execute_reply": "2021-11-24T16:50:17.558690Z",
     "shell.execute_reply.started": "2021-11-24T16:49:53.531244Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOR SESSION] Creating new TOR Session. Please give it a couple of seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:torpy.cell_socket:timed out\n",
      "ERROR:root:[ignored]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/cell_socket.py\", line 63, in connect\n",
      "    self._socket.connect((self._router.ip, self._router.or_port))\n",
      "  File \"/home/mage/Hacking/miniconda3/lib/python3.7/ssl.py\", line 1172, in connect\n",
      "    self._real_connect(addr, False)\n",
      "  File \"/home/mage/Hacking/miniconda3/lib/python3.7/ssl.py\", line 1159, in _real_connect\n",
      "    super().connect(addr)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/utils.py\", line 79, in newfn\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/consesus.py\", line 235, in renew\n",
      "    raw_string = self.download_consensus(prev_hash)\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/consesus.py\", line 183, in newfn\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/consesus.py\", line 390, in download_consensus\n",
      "    with self._get_dir_client() as dir_client:\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/consesus.py\", line 375, in _get_dir_client\n",
      "    self._dir_guard, self._dir_circuit = self._create_dir_circuit(purpose='Internal dir client')\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/consesus.py\", line 365, in _create_dir_circuit\n",
      "    guard = TorGuard(router, purpose=purpose)\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/guard.py\", line 66, in __init__\n",
      "    self.__tor_socket.connect()\n",
      "  File \"/home/mage/.local/lib/python3.7/site-packages/torpy/cell_socket.py\", line 69, in connect\n",
      "    raise TorSocketConnectError(e)\n",
      "torpy.cell_socket.TorSocketConnectError: timed out\n",
      "WARNING:torpy.utils:Retry with another router...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOR SESSION] Creating new TOR Session. Please give it a couple of seconds...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<twint.run.Twint at 0x7f0d31951550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "c = twint.Config()\n",
    "c.Username = 'deepfates'\n",
    "tweets = []\n",
    "c.Store_object = True\n",
    "c.Store_object_tweets_list = tweets\n",
    "c.Since = last_date\n",
    "c.Hide_output = True\n",
    "twint.run.Profile(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the configuration necessary to grab my tweets. Have to use `Hide_output = True`, or it will print every single tweet in the output. \n",
    "\n",
    "\n",
    "I now have a dataset of tweets. Let's explore one here, and see some of its metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.564258Z",
     "iopub.status.busy": "2021-11-24T16:50:17.563655Z",
     "iopub.status.idle": "2021-11-24T16:50:17.568163Z",
     "shell.execute_reply": "2021-11-24T16:50:17.567698Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.564177Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2937"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.569038Z",
     "iopub.status.busy": "2021-11-24T16:50:17.568878Z",
     "iopub.status.idle": "2021-11-24T16:50:17.570993Z",
     "shell.execute_reply": "2021-11-24T16:50:17.570683Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.569022Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = tweets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.571736Z",
     "iopub.status.busy": "2021-11-24T16:50:17.571619Z",
     "iopub.status.idle": "2021-11-24T16:50:17.575758Z",
     "shell.execute_reply": "2021-11-24T16:50:17.575299Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.571720Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1463016921280958471',\n",
       " '2021-11-23',\n",
       " '2021-11-23 08:26:11 MST',\n",
       " 1463166997525630991,\n",
       " 1,\n",
       " 'https://twitter.com/deepfates/status/1463166997525630991',\n",
       " [],\n",
       " [],\n",
       " '',\n",
       " 1,\n",
       " [{'screen_name': 'astraniqe', 'name': 'Cari', 'id': '1197295952752730112'}],\n",
       " False,\n",
       " '',\n",
       " '',\n",
       " 0,\n",
       " '',\n",
       " '',\n",
       " '08:26:11',\n",
       " '-0700',\n",
       " '@astraniqe probably pillarcat u',\n",
       " [],\n",
       " 3315205122,\n",
       " '3315205122',\n",
       " '',\n",
       " '',\n",
       " 'deepfates',\n",
       " 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.conversation_id, t.datestamp, t.datetime, t.id, t.likes_count, t.link, t.mentions, t.photos, t.quote_url, t.replies_count, t.reply_to, t.retweet, t.retweet_date, t.retweet_id, t.retweets_count, t.source, t.thumbnail, t.timestamp, t.timezone, t.tweet, t.urls, t.user_id, t.user_id_str, t.user_rt, t.user_rt_id, t.username, t.video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tweet layout functions\n",
    "\n",
    "Many of my tweets have pictures or memes attached, but Twitter only includes the pic.twitter.com URL for these. Here I build a few functions to download the image and squeeze it into a Markdown template for display on my site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.576668Z",
     "iopub.status.busy": "2021-11-24T16:50:17.576476Z",
     "iopub.status.idle": "2021-11-24T16:50:17.579199Z",
     "shell.execute_reply": "2021-11-24T16:50:17.578662Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.576647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.580143Z",
     "iopub.status.busy": "2021-11-24T16:50:17.579956Z",
     "iopub.status.idle": "2021-11-24T16:50:17.585840Z",
     "shell.execute_reply": "2021-11-24T16:50:17.585401Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.580116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dl_image(url):\n",
    "    filename = '../images/from_twitter/' + url.split('/')[-1]\n",
    "    r = requests.get(url, stream = True)\n",
    "    if r.status_code == 200:\n",
    "        r.raw.decode_content = True\n",
    "        with open(filename,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "        return(filename)\n",
    "    else:\n",
    "        return(None)\n",
    "    \n",
    "# hacky thing uses [1:] to shave the first '.' off the filename\n",
    "def image_template(filename):\n",
    "    return(f'![image from twitter]({filename[2:]})\\n')\n",
    "\n",
    "    \n",
    "def get_tweet(t):\n",
    "    if t.photos == []:\n",
    "        img_md = ''\n",
    "    else:\n",
    "        img_list = [dl_image(url) for url in t.photos]\n",
    "        img_md = '\\n'.join([image_template(o) for o in img_list])\n",
    "\n",
    "    return(f'''\n",
    "#### <a href = \"{t.link}\">*{t.timestamp}*</a>\n",
    "\n",
    "<font size=\"5\">{t.tweet}</font>\n",
    "\n",
    "{img_md}\n",
    "\n",
    "🗨️ {t.replies_count} ♺ {t.retweets_count} 🤍  {t.likes_count}   \n",
    "\n",
    "---\n",
    "    ''')\n",
    "\n",
    "def get_md(tweets, date):\n",
    "    tweets_text = ''.join(t for t in tweets)\n",
    "    return(f'''---\n",
    "title: deepfates log {date}\n",
    "layout: post\n",
    "toc: true\n",
    "comments: false\n",
    "search_exclude: false\n",
    "hide: true\n",
    "categories: [tweets]\n",
    "---\n",
    "\n",
    "{tweets_text}\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.586650Z",
     "iopub.status.busy": "2021-11-24T16:50:17.586517Z",
     "iopub.status.idle": "2021-11-24T16:50:17.589636Z",
     "shell.execute_reply": "2021-11-24T16:50:17.589009Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.586633Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.590691Z",
     "iopub.status.busy": "2021-11-24T16:50:17.590521Z",
     "iopub.status.idle": "2021-11-24T16:50:17.594773Z",
     "shell.execute_reply": "2021-11-24T16:50:17.594273Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.590671Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesterday = t.datestamp\n",
    "y_tweets = [tw for tw in tweets if tw.datestamp == yesterday]\n",
    "len(y_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.595557Z",
     "iopub.status.busy": "2021-11-24T16:50:17.595421Z",
     "iopub.status.idle": "2021-11-24T16:50:17.599437Z",
     "shell.execute_reply": "2021-11-24T16:50:17.598939Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.595540Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### <a href = \"https://twitter.com/deepfates/status/1463166997525630991\">*08:26:11*</a>\n",
       "\n",
       "<font size=\"5\">@astraniqe probably pillarcat u</font>\n",
       "\n",
       "\n",
       "\n",
       "🗨️ 1 ♺ 0 🤍  1   \n",
       "\n",
       "---\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(get_tweet([tw for tw in tweets if tw.datestamp == yesterday][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.600222Z",
     "iopub.status.busy": "2021-11-24T16:50:17.600073Z",
     "iopub.status.idle": "2021-11-24T16:50:17.602488Z",
     "shell.execute_reply": "2021-11-24T16:50:17.602016Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.600185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_sorted = sorted(y_tweets, key=lambda x: x.datetime)\n",
    "# [tweet.tweet for tweet in y_sorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many replies! Let's limit to just mine for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.603343Z",
     "iopub.status.busy": "2021-11-24T16:50:17.603198Z",
     "iopub.status.idle": "2021-11-24T16:50:17.605847Z",
     "shell.execute_reply": "2021-11-24T16:50:17.605408Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.603326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_md = get_md([get_tweet(t) for t in y_sorted if \"@\" not in t.tweet], yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.606705Z",
     "iopub.status.busy": "2021-11-24T16:50:17.606573Z",
     "iopub.status.idle": "2021-11-24T16:50:17.610168Z",
     "shell.execute_reply": "2021-11-24T16:50:17.609359Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.606688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5907"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.611059Z",
     "iopub.status.busy": "2021-11-24T16:50:17.610899Z",
     "iopub.status.idle": "2021-11-24T16:50:17.614961Z",
     "shell.execute_reply": "2021-11-24T16:50:17.614041Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.611040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'../_posts/tweets/{yesterday}-tweets.md', 'w') as f:\n",
    "    print(y_md, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the work\n",
    "\n",
    "Okay, that'll do for now. It prints a chronological page of tweets for each day.\n",
    "\n",
    "I'll wrap that behavior in a function and pass it my tweets and a set of dates when i have tweeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.616266Z",
     "iopub.status.busy": "2021-11-24T16:50:17.615992Z",
     "iopub.status.idle": "2021-11-24T16:50:17.621160Z",
     "shell.execute_reply": "2021-11-24T16:50:17.620374Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.616232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_day_page(day, tweets):\n",
    "    tweets = [tw for tw in tweets if tw.datestamp == day]\n",
    "    sorted_tweets = sorted(tweets, key=lambda x: x.datetime)\n",
    "    md = get_md([get_tweet(t) for t in sorted_tweets], day)\n",
    "    with open(f'../_posts/tweets/{day}-tweets.md', 'w') as f:\n",
    "        print(md, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.622432Z",
     "iopub.status.busy": "2021-11-24T16:50:17.622172Z",
     "iopub.status.idle": "2021-11-24T16:50:17.629060Z",
     "shell.execute_reply": "2021-11-24T16:50:17.628024Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.622400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tweets = [t for t in tweets if \"@\" not in t.tweet]\n",
    "\n",
    "len(self_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.630340Z",
     "iopub.status.busy": "2021-11-24T16:50:17.630096Z",
     "iopub.status.idle": "2021-11-24T16:50:17.635144Z",
     "shell.execute_reply": "2021-11-24T16:50:17.634548Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.630310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = set([t.datestamp for t in self_tweets])\n",
    "\n",
    "len(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.636029Z",
     "iopub.status.busy": "2021-11-24T16:50:17.635901Z",
     "iopub.status.idle": "2021-11-24T16:50:17.640187Z",
     "shell.execute_reply": "2021-11-24T16:50:17.639724Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.636013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:17.641203Z",
     "iopub.status.busy": "2021-11-24T16:50:17.641025Z",
     "iopub.status.idle": "2021-11-24T16:50:43.431445Z",
     "shell.execute_reply": "2021-11-24T16:50:43.430980Z",
     "shell.execute_reply.started": "2021-11-24T16:50:17.641179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:17<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for day in tqdm(days):\n",
    "    write_day_page(day, self_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would also like to do analysis to see how often I tweet, and other facts. And maybe make a big list of links. Maybe next time.\n",
    "\n",
    "For now you can find these secret tweet archives by searching in the [Explore](/explore) page. The days archived this time are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-24T16:50:43.432350Z",
     "iopub.status.busy": "2021-11-24T16:50:43.432229Z",
     "iopub.status.idle": "2021-11-24T16:50:43.435236Z",
     "shell.execute_reply": "2021-11-24T16:50:43.434790Z",
     "shell.execute_reply.started": "2021-11-24T16:50:43.432334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2021-11-23',\n",
       " '2021-11-24',\n",
       " '2021-11-25',\n",
       " '2021-11-26',\n",
       " '2021-11-27',\n",
       " '2021-11-28',\n",
       " '2021-11-29',\n",
       " '2021-11-30',\n",
       " '2021-12-01',\n",
       " '2021-12-02',\n",
       " '2021-12-03',\n",
       " '2021-12-04',\n",
       " '2021-12-05',\n",
       " '2021-12-06',\n",
       " '2021-12-07',\n",
       " '2021-12-08',\n",
       " '2021-12-09',\n",
       " '2021-12-10',\n",
       " '2021-12-11',\n",
       " '2021-12-12',\n",
       " '2021-12-13',\n",
       " '2021-12-14',\n",
       " '2021-12-15',\n",
       " '2021-12-16',\n",
       " '2021-12-17',\n",
       " '2021-12-18',\n",
       " '2021-12-19',\n",
       " '2021-12-20'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
